<h1 align="center"><strong>TASTE-Rob: Advancing Video Generation of Task-Oriented Hand-Object Interaction for Generalizable Robotic Manipulation
</strong></h1>
<p align="center">
      <strong><span style="color: red;">CVPR 2025</span></strong>
    <br>
    <a href='https://hong-xiang-cv.github.io/' target='_blank'>Hongxiang Zhao*</a>&emsp;
    Xingchen Liu*</a>&emsp;
    <a href='https://mutianxu.github.io/' target='_blank'>Mutian Xu</a>&emsp;
    <a href='https://scholar.google.com/citations?user=mlu1Oo4AAAAJ&hl=en' target='_blank'>Yiming Hao</a>&emsp;
    Weikai Chen</a>&emsp;
    <a href='https://gaplab.cuhk.edu.cn/' target='_blank'>Xiaoguang HanÂ§</a>&emsp;
    <br>
    CUHKSZ <a href='https://gaplab.cuhk.edu.cn/' target='_blank'>GAP-Lab</a>   
    <br>
    *Indicates Equal Contribution Â§Indicates Corresponding Author
    <br>
  </p>

<p align="center">
  <a href="https://taste-rob.github.io/"><b>ðŸ“– Project Page</b></a> |
  <a href="https://arxiv.org/abs/2503.11423"><b>ðŸ“„ Paper Link</b></a>
</p>

</div>

> We introduce TASTE-Rob: 1) a dataset with 100,856 task-oriented hand-object interaction videos, 2) a three-stage pose-refinement video generation pipeline. With the above contributions, TASTE-Rob is able to generate realistic interactions and support the possibility of transferring on robots.

<div align="center">
    <img src="assets/teaser.png" height=500>
</div>

## ðŸ“£ News
- [3/14/2025] TASTE-Rob has been released on Arxiv now!!!
- [2/27/2025] ðŸŽ‰ðŸŽ‰ðŸŽ‰TASTE-Rob has been accepted by CVPR 2025!!!ðŸŽ‰ðŸŽ‰ðŸŽ‰

## ðŸš© Plan
- [x] Paper Released.
- [ ] Dataset will be released before ``05/05/2025``.
- [ ] Source Code and Pretrained Weights.
